{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17ad57b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db29f4c8",
   "metadata": {},
   "source": [
    "gathering the first dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c713042e",
   "metadata": {},
   "source": [
    "#make a file path for the file if it is not available \n",
    "folder_name = 'image_predictions_folder'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "    \n",
    "url = \"https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c2e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the file \n",
    "with open(os.path.join(folder_name,\n",
    "                      url.split('/')[-1]) , mode='wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aebc97",
   "metadata": {},
   "source": [
    "gathering the second dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7159a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_arc = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "twit_arc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ea3424",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "gathering the third dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bfd3a3",
   "metadata": {},
   "source": [
    "THE cell below is used to query twitter api to get the favorite_count and \n",
    "retweet_count for the using the tweet id from the second dataset.\n",
    "NB. the scret tokens are incomplete in compliance with the terms and conditions of twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec79419",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n",
    "# These are are not complete to comply with Twitter's API terms and conditions\n",
    "access_token= '153954C'\n",
    "access_secret = 'R1hOD'\n",
    "consumer_key  = '7xdHjD'\n",
    "consumer_secret= 'CWz8uu\\'\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "tweet_ids = df_1.tweet_id.values\n",
    "len(tweet_ids)\n",
    "\n",
    "# Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "count = 0\n",
    "fails_dict = {}\n",
    "start = timer()\n",
    "# Save each tweet's returned JSON as a new line in a .txt file\n",
    "with open('tweet_json.txt', 'w') as outfile:\n",
    "    # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "    for tweet_id in tweet_ids:\n",
    "        count += 1\n",
    "        print(str(count) + \": \" + str(tweet_id))\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            print(\"Success\")\n",
    "            json.dump(tweet._json, outfile)\n",
    "            outfile.write('\\n')\n",
    "        except  tweepy.errors.TweepyException as e: \n",
    "            print(\"Fail\")\n",
    "            fails_dict[tweet_id] = e\n",
    "            pass\n",
    "end = timer()\n",
    "print(end - start)\n",
    "print(fails_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdef2ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "image_pred = pd.read_csv('image_predictions_folder/image-predictions.tsv', sep='\\t')\n",
    "image_pred.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcbb1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_arc = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "twit_arc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebb3448",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_tweet = pd.read_json(\"tweet-json.txt\", lines = True,dtype ={\"id_str\": str})[:-1]\n",
    "api_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8072d3a3",
   "metadata": {},
   "source": [
    "After viewing the json data in a text editor acquired using twitter api i have\n",
    "decided to extract only the favorite count and retweet count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed55bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "df_list = []\n",
    "\n",
    "\n",
    "with open('tweet-json.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        tweets = json.loads(line)\n",
    "        ids =  {'tweet_id':tweets['id'] ,\n",
    "                'favorite_count': tweets['favorite_count'], \n",
    "                'retweet_count':tweets['retweet_count']}\n",
    "        df_list.append(ids)\n",
    "tweet_api = pd.DataFrame(df_list)\n",
    "tweet_api\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a83ea5",
   "metadata": {},
   "source": [
    "we now have three data frames which are\n",
    " 1. image_pred\n",
    " 2. twit_arc\n",
    " 3. tweet_api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b4703e",
   "metadata": {},
   "source": [
    "# ASSESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02cb264",
   "metadata": {},
   "source": [
    "###### Assesing the image prediction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014aff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual assesment\n",
    "image_pred.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bcee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab546f0",
   "metadata": {},
   "source": [
    "issues\n",
    "\n",
    "* inconsistent case-type for values p1,p2 and p3 columns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2a2d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pred.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92517029",
   "metadata": {},
   "source": [
    "issues\n",
    "\n",
    "* tweet_id should be string not int\n",
    "* jpg_url should be image_url so that it can be descriptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e21b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_pred.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d2b7bb",
   "metadata": {},
   "source": [
    "issues\n",
    "\n",
    "* some rows have p1_dog,p2_dog,p3_dog ratings as False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21cc251",
   "metadata": {},
   "source": [
    "##### Assesing the tweet from twitter api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35300231",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_api.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2b6a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_api.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13733d4",
   "metadata": {},
   "source": [
    "issues\n",
    "\n",
    "* tweet_id should be string not int\n",
    "* favorite count and retweet count should be int not float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57ab4ff",
   "metadata": {},
   "source": [
    "Assessing the twitter archive enhanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799a014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327b85c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twit_arc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f627026",
   "metadata": {},
   "source": [
    "Issues\n",
    "\n",
    "* tweet_id should str not int\n",
    "* timestamp should be \"data time\" not \"str\"\n",
    "* we have 2356 entries here which means the data in the other two dataset are incomplete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f61e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_arc.query('rating_numerator > 15')['rating_numerator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc36f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_arc['rating_numerator'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb83ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_arc['rating_numerator'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2f3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual assesment\n",
    "twit_arc.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f4087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f8e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_arc.query('rating_numerator >15')[['rating_numerator','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc037d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_arc.query('rating_denominator != 10 ')[['rating_denominator','text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99294782",
   "metadata": {},
   "source": [
    "issues\n",
    "* 466 numerator ratings are less than 10 0r greater than 15.Since 15 is the highest rating on weratedog on twitter.\n",
    "* 23 denominator rating are not equal to 10 \n",
    "* Nulls represented as (none) in name column \n",
    "* some columns are not needed in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bf8111",
   "metadata": {},
   "source": [
    "issues \n",
    "* doggo, flo0fer,pupper,puppo are dog stages which should be under a variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5072e320",
   "metadata": {},
   "source": [
    "#### Grouping the issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489380e0",
   "metadata": {},
   "source": [
    "QUALITY ISSUES\n",
    "* image_pred\n",
    "    - inconsistent case-type for values p1,p2 and p3 columns. \n",
    "    - tweet_id should be string not int.\n",
    "    - incomplete data.\n",
    "###### \n",
    "* twit_arc\n",
    "    - tweet_id should be string not int.\n",
    "    - incomplete data.   \n",
    "######  \n",
    "* tweet_api dataset\n",
    "    - some numerator ratings are greater than 15 from vissual assesment.Since 15 is the highest rating on weratedog twitter.\n",
    "    - 23 denominator rating are not equal to 10.\n",
    "    - Nulls represented as (none) in some columns. \n",
    "    - some columns are not needed in this dataset for our insight and visualization.\n",
    "    - tweet_id is duplicated\n",
    "    \n",
    "    \n",
    "TIDINESS ISSUES\n",
    "* image_pred\n",
    "    - jpg_url should be image_url so that it can be descriptive (tidy)\n",
    "    - p_conf is not descriptive of the columns in the image_pred dataset.   \n",
    "###### \n",
    "* tweet_api dataset\n",
    "    - doggo, floofer,pupper,puppo are dog stages which should be under a variable.\n",
    "    - all dataset shoud be 1 dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9516b224",
   "metadata": {},
   "source": [
    "# CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc270c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copies of the dataset so as to preserve the original dataset.\n",
    "twit_arc_cln = twit_arc.copy()\n",
    "img_pred_cln = image_pred.copy()\n",
    "tweet_api_cln = tweet_api.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3c6079",
   "metadata": {},
   "source": [
    "## Tidiness\n",
    "#### twit_arc:doggo, floofer,pupperand puppo are dog stages which should be under a variable.\n",
    " \n",
    "#### Define\n",
    "- extract the stage of dogs from the tweet text irrespective of the case_type.\n",
    "- drop the doggo, floofer,pupper and puppo \n",
    "- convert the values in the stage of dogs to lower-case for consistency.\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77635216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "twit_arc_cln['dog_stage'] = twit_arc_cln['text'].str.extract(r'(doggo|floofer|pupper|puppo)', flags = re.IGNORECASE)\n",
    "twit_arc_cln = twit_arc_cln.drop(columns=['doggo','floofer','pupper','puppo'])\n",
    "twit_arc_cln['dog_stage'] =twit_arc_cln['dog_stage'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8079a8",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdcca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_arc_cln.sample(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a425521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_arc_cln['dog_stage'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9d3e7f",
   "metadata": {},
   "source": [
    "## Tidiness\n",
    "#### image_pred_cln and tweet_api_cln:\n",
    "- all dataset shoud be 1 dataset \n",
    "- tweet_id is duplicated \n",
    "#### Define\n",
    "* merge the three dataset together on the tweet_id column.\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384eb5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_arc_cln = pd.merge(twit_arc_cln, img_pred_cln , on= \"tweet_id\" , how=\"left\") \n",
    "new_twit_arc_cln = pd.merge(twit_arc_cln , tweet_api_cln , on= \"tweet_id\" , how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eb9df2",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f02f935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_twit_arc_cln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd2907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_twit = new_twit_arc_cln.copy()\n",
    "merged_twit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26dbec0",
   "metadata": {},
   "source": [
    "## Tidiness \n",
    "#### some columns are not needed for the insights we want to make.\n",
    "#### Define\n",
    "* drop unused columns\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b63f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_twit.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afff295",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_twit.drop(columns=['in_reply_to_status_id','in_reply_to_user_id',\n",
    "                          'retweeted_status_id', 'retweeted_status_user_id',\n",
    "                          'retweeted_status_timestamp', 'expanded_urls'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26768ed",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80343d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_twit.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4946b052",
   "metadata": {},
   "source": [
    "## Quality \n",
    "#### null values represented as none\n",
    "#### Define\n",
    "* replace the none values as np.nan\n",
    "\n",
    "#### Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824474f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "merged_twit = merged_twit.replace(\"None\", value = np.nan )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0630951",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a10a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_twit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79954ffd",
   "metadata": {},
   "source": [
    "## Quality \n",
    "#### 23 denominator rating are not equal to 10\n",
    "#### Define\n",
    "* change all the values in the denominator rating to 10 since the ratings always 10 .\n",
    "\n",
    "#### Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef7bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_twit.rating_denominator = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a33b347",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec54ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_twit.rating_denominator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b10d831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1f93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beec2169",
   "metadata": {},
   "source": [
    "## Quality \n",
    "#### some numerator ratings greater than 15\n",
    "#### Define\n",
    "* check for how many numerator ratings greater than 15.\n",
    "* change it manually if possible otherwise programatically.\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cd1256",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "less_15 = merged_twit.query('rating_numerator > 15')['rating_numerator']\n",
    "#to get the index of the values\n",
    "val = less_15.index.values.tolist()\n",
    "len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d6aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_twit.query('rating_numerator > 15')[['text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44773448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the above cells there are 26 cells with numerator ratings greater than 15 \n",
    "# we go through the text and get the rating_numerator from it \n",
    "# some of the ratings are group ratings so we find the ratio. the others are \n",
    "#replaced by the median of the numerator ratings which is 11\n",
    "\n",
    "\n",
    "#list of correct ratings from the text\n",
    "correct_list = [13,11,11,11,13,9.75,12,11,9.75,11.27,11,11,12,11,11,10,9,12,11,11,12.5,11.26,12,11,11,12]\n",
    "\n",
    "for i in range(26):\n",
    "        merged_twit.rating_numerator[val[i]]=correct_list[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4730bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_twit.rating_numerator.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32666aec",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f12e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_twit.rating_numerator.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bbf29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_twit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6246cae8",
   "metadata": {},
   "source": [
    "## Quality \n",
    "####  inconsistent case-type for values p1,p2 and p3 columns\n",
    "#### Define\n",
    "* change the case of all the data in p1,p2,p3 to title case\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527ef648",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_twit.p1 = merged_twit.p1.str.title()\n",
    "merged_twit.p2 = merged_twit.p2.str.title()\n",
    "merged_twit.p3 = merged_twit.p3.str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1831d8db",
   "metadata": {},
   "source": [
    "#### Test\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4af634",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_twit[['p1','p2','p3']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b0af75",
   "metadata": {},
   "source": [
    "## Quality\n",
    "##### tweet_id should string not int\n",
    "#####  timestamp should be date_time not str\n",
    "#### favorite count and retweet count should be int not float\n",
    "#### Define\n",
    "* change the type of tweet_id to str\n",
    "* convert the column type using to_datetime method \n",
    "* convert favorite count and retweet count type to int \n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96390b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_twit['tweet_id'] = merged_twit['tweet_id'].astype(str)\n",
    "merged_twit['timestamp']= pd.to_datetime(merged_twit['timestamp'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a2886f",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e41f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_twit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba81c8a",
   "metadata": {},
   "source": [
    "## Quality\n",
    "##### jpg_url should be image_url so that it can be descriptive (tidy)\n",
    "#####    p1_conf,p2_conf,p3_conf is not descriptive of the columns in the  dataset.\n",
    "\n",
    "#### Define\n",
    "* rename the columns\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f23eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_twit.rename(columns={'p1_conf': 'p1_confidence'}, inplace=True)\n",
    "merged_twit.rename(columns={'p2_conf': 'p2_confidence'}, inplace=True)\n",
    "merged_twit.rename(columns={'p3_conf': 'p3_confidence'}, inplace=True)\n",
    "merged_twit.rename(columns={'jpg_url': 'image_url'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c33a70",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eba8c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_twit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55af0886",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b04a9eea",
   "metadata": {},
   "source": [
    "#### save data to master_twitter_archive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ce262",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_twit.to_csv('master_twitter_archive.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a277b855",
   "metadata": {},
   "source": [
    "# Analysis And visulization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea9509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df= pd.read_csv('master_twitter_archive.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd721b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f00af4",
   "metadata": {},
   "source": [
    "###  The top 10 most predicted breed of dog from  all the three predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a7c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the value_counts for all breed from three predictions\n",
    "dfc = df.p1.value_counts()+df.p2.value_counts()+df.p3.value_counts()\n",
    "dfc.sort_values(ascending = False)[:10].plot(kind = 'bar',width = 0.8, figsize = (10,5));\n",
    "plt.xlabel('Dog Breed',fontsize= 14),plt.ylabel('Number of Pictures',fontsize= 14),\n",
    "plt.title('Top 10 breeds with the most number of pictures'.title(),fontsize= 14);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f94c4cd",
   "metadata": {},
   "source": [
    "### percentage of pictures predicted to be dog's by each prediction .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7e16f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_dog(pred):\n",
    "    return df[pred][df[pred] == True].count()/df[pred].count()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5b4629",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'percentage of pictures predicted to be dog pictures by p1 is {is_dog(\"p1_dog\")}')\n",
    "print(f'percentage of pictures predicted to be dog pictures by p2 is {is_dog(\"p2_dog\")}')\n",
    "print(f'percentage of pictures predicted to be dog pictures by p3 is {is_dog(\"p3_dog\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc80c678",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie([is_dog('p1_dog'),is_dog('p2_dog'),is_dog('p3_dog')],labels=('p1','p2','p3'), explode = [0.1,0.1,0.1],autopct ='%1.1f%%')\n",
    "plt.title(\"percentage of pictures predicted to be dog's by each prediction\".title(), fontsize= 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03dae91",
   "metadata": {},
   "source": [
    "##### Insight\n",
    "From this we can seee that the probility of a picture being predicted to be dog picture for the three predictions are closed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be30d213",
   "metadata": {},
   "source": [
    "### Most common rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b6afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rating_numerator.value_counts().plot(kind= 'bar', figsize = (10,6));\n",
    "plt.xlabel('Ratings',fontsize= 14,);\n",
    "plt.ylabel('Pictures',fontsize= 14);\n",
    "plt.title('Number of pictures for each rating',fontsize= 14);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f07e14b",
   "metadata": {},
   "source": [
    "##### Insight\n",
    "Rating of 12 is the most common rating given to dogs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7d9a54",
   "metadata": {},
   "source": [
    "### Dog Stage with the most number of pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfebd71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dog_stage.value_counts().plot(kind= 'bar');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01dee9b",
   "metadata": {},
   "source": [
    "dog that are at the stage of pupper are the most followed by doggo, puppo and floofer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd57d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dog_stage(col):\n",
    "    g = df.groupby('dog_stage')[col].mean().sort_values()\n",
    "    g.plot(kind = 'bar')\n",
    "    plt.ylabel(col.title(),fontsize= 14,);\n",
    "    plt.xlabel('Dog_stage',fontsize= 14);\n",
    "    plt.title(f'Average {col} Per Dog_Stage',fontsize= 14);\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc006642",
   "metadata": {},
   "source": [
    "### Dog Stage with the highest average rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c340c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_stage('rating_numerator')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc8fa7a",
   "metadata": {},
   "source": [
    "On average picture in 'puppo' dog stage get most rating. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041b607",
   "metadata": {},
   "source": [
    "### Dog Stage with the highest average favorite_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74afba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dog_stage('favorite_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ecb697",
   "metadata": {},
   "source": [
    "##### Insight\n",
    "On average picture in 'puppo' dog stage get most likes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cf1646",
   "metadata": {},
   "source": [
    "### Relationship between favorite_count , retweet_count and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f892bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rel(col_a,col_b) : \n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    col_a: first column\n",
    "    col_b : second column.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    A scatter chart showing the correlation between col_a and col_b\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    #import statsmodels.api as sn\n",
    "    import scipy  \n",
    "    #To get the statistacal correlation between the two columns, we need to drop the null valuues in the two columns\n",
    "    c = df[[col_a,col_b]].dropna()\n",
    "    print(f'correlation between {col_a} and {col_b} is' , scipy.stats.pearsonr(c[col_a],c[col_b])[0])\n",
    "    sns.set_theme(color_codes=True)\n",
    "    #To plot a scatter chart\n",
    "    sns.regplot(x=col_a, y= col_b, data=c, marker=\"o\", \n",
    "                scatter_kws={\"s\": 50 });\n",
    "    sns.set(rc={'figure.figsize':(6,4)})\n",
    "    plt.xlabel(col_a.title(), fontsize=12)\n",
    "    plt.ylabel(col_b.title(), fontsize=12);\n",
    "    plt.title(f'relationship between {col_a} and {col_b}'.title(), fontsize=12);\n",
    "    \n",
    "    #print('correlation between col_a and col_b is' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb391ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PLOT 1')\n",
    "# Relationship between favorite_count and retweet_count\n",
    "plot_rel('retweet_count','favorite_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a04a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PLOT 2')\n",
    "# Relationship between favorite_count and retweet_count\n",
    "plot_rel('rating_numerator','favorite_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a969405",
   "metadata": {},
   "source": [
    "### Summary\n",
    "* from plot 1. there is ahigh correlation of 0.703 between favorite count and retweet count.  \n",
    "* From the two plots below puppo has most likes and ratings which means pictures in puppo stage tend to get more likes and ratings and equally more retweets on average since their is a high correlation  between favorite_count and retweet_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a5d736",
   "metadata": {},
   "source": [
    "### Limitations.\n",
    "\n",
    "* p1, p2,p3 are 100% accurate which means some of their prediction might be r=wrong which would have affected our result.\n",
    "* Also many ofthe pictures dont have dog_stages which would have affected the result of our analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
